{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a52c80c4-1ea2-4d1e-b582-fac51081e76d",
      "metadata": {
        "id": "a52c80c4-1ea2-4d1e-b582-fac51081e76d"
      },
      "source": [
        "<center><img src=https://raw.githubusercontent.com/feast-dev/feast/master/docs/assets/feast_logo.png width=400/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "576a8e30-fe4c-4eda-bc56-9edd7fde3385",
      "metadata": {
        "id": "576a8e30-fe4c-4eda-bc56-9edd7fde3385"
      },
      "source": [
        "# Credit Risk Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f3fbd5a-1587-4b4e-9263-a57490657337",
      "metadata": {
        "id": "1f3fbd5a-1587-4b4e-9263-a57490657337"
      },
      "source": [
        "Predicting credit risk is an important task for financial institutions. If a bank can accurately determine the probability that a borrower will pay back a future loan, then they can make better decisions on loan terms and approvals. Getting credit risk right is critical to offering good financial services, and getting credit risk wrong could mean going out of business.\n",
        "\n",
        "AI models have played a central role in modern credit risk assessment systems. In this example, we develop a credit risk model to predict whether a future loan will be good or bad, given some context data (presumably supplied from the loan application). We use the modeling process to demonstrate how Feast can be used to facilitate the serving of data for training and inference use-cases.\n",
        "\n",
        "In this notebook, we prepare the data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d05715f-ddb8-42de-8f0c-212dcbad9e0e",
      "metadata": {
        "id": "4d05715f-ddb8-42de-8f0c-212dcbad9e0e"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fba29f9-db1f-4ceb-b066-5b2df2c95d33",
      "metadata": {
        "id": "6fba29f9-db1f-4ceb-b066-5b2df2c95d33"
      },
      "source": [
        "*The following code assumes that you have read the example README.md file, and that you have setup an environment where the code can be run. Please make sure you have addressed the prerequisite needs.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8a897b19-6f82-4631-ae51-8a23182ff267",
      "metadata": {
        "id": "8a897b19-6f82-4631-ae51-8a23182ff267"
      },
      "outputs": [],
      "source": [
        "# Import Python libraries\n",
        "import os\n",
        "import warnings\n",
        "import datetime as dt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b944ed48-54b3-43fa-8373-ce788d7e71af",
      "metadata": {
        "id": "b944ed48-54b3-43fa-8373-ce788d7e71af"
      },
      "outputs": [],
      "source": [
        "# suppress warning messages for example flow (don't run if you want to see warnings)\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "70788c73-144f-4ecf-b370-c5669c538d93",
      "metadata": {
        "id": "70788c73-144f-4ecf-b370-c5669c538d93"
      },
      "outputs": [],
      "source": [
        "# Seed for reproducibility\n",
        "SEED = 142"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfb4dfd0-f583-4aa0-bd39-3ff9fbb80db0",
      "metadata": {
        "id": "cfb4dfd0-f583-4aa0-bd39-3ff9fbb80db0"
      },
      "source": [
        "### Pull the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c206dfc-d551-4002-ae63-ccbb981768fa",
      "metadata": {
        "id": "3c206dfc-d551-4002-ae63-ccbb981768fa"
      },
      "source": [
        "The data we will use to train the model is from the [OpenML](https://www.openml.org/) dataset [credit-g](https://www.openml.org/search?type=data&sort=runs&status=active&id=31), obtained from a 1994 German study. More details on the data can be found in the `DESC` attribute and `details` map (see below)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "31a9e964-bdb3-4ae4-b2b4-64bbe0ab93a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31a9e964-bdb3-4ae4-b2b4-64bbe0ab93a3",
        "outputId": "b7c16525-1dec-4111-d851-60a522f08456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using temporary data_home: /tmp/tmp4dxm95cf\n",
            "Retrying data fetch with temporary data_home...\n",
            "Error fetching data with temporary data_home: md5 checksum of local file for data/v1/download/31 does not match description: expected: 9a475053fed0c26ee95cd4525e50074c but got 4faec5c39a1f821270a5878880fbfc8c. Downloaded file could have been modified / corrupted, clean cache and retry...\n",
            "Cleaning up temporary data_home: /tmp/tmp4dxm95cf\n"
          ]
        }
      ],
      "source": [
        "import tempfile\n",
        "import shutil\n",
        "\n",
        "# Create a temporary directory for data_home\n",
        "temp_data_home = tempfile.mkdtemp()\n",
        "print(f\"Using temporary data_home: {temp_data_home}\")\n",
        "\n",
        "# Set the SCIKIT_LEARN_DATA environment variable to the temporary directory\n",
        "os.environ['SCIKIT_LEARN_DATA'] = temp_data_home\n",
        "\n",
        "try:\n",
        "    print(\"Retrying data fetch with temporary data_home...\")\n",
        "    data = fetch_openml(name=\"credit-g\", version=1, parser='auto')\n",
        "    print(\"Data fetched successfully with temporary data_home!\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error fetching data with temporary data_home: {e}\")\n",
        "finally:\n",
        "    # Clean up the temporary directory\n",
        "    print(f\"Cleaning up temporary data_home: {temp_data_home}\")\n",
        "    shutil.rmtree(temp_data_home)\n",
        "    # Unset the SCIKIT_LEARN_DATA environment variable to revert to default behavior\n",
        "    if 'SCIKIT_LEARN_DATA' in os.environ:\n",
        "        del os.environ['SCIKIT_LEARN_DATA']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a698410f",
        "outputId": "afa5c0fa-fed4-4e96-eec7-cdcdc34aafdf"
      },
      "source": [
        "import hashlib\n",
        "import os\n",
        "from sklearn.datasets import get_data_home\n",
        "\n",
        "# Get the scikit-learn data home directory\n",
        "data_home = get_data_home()\n",
        "\n",
        "# Construct the path to the downloaded file for 'credit-g'\n",
        "# The path is usually data_home/openml/openml.org/data/v1/download/{data_id}\n",
        "# From the error message, the data_id is 31.\n",
        "file_path = os.path.join(data_home, \"openml\", \"openml.org\", \"data\", \"v1\", \"download\", \"31\")\n",
        "\n",
        "print(f\"Checking MD5 for file: {file_path}\")\n",
        "\n",
        "# Check if the file exists\n",
        "if not os.path.exists(file_path):\n",
        "    print(\"Error: File not found at the specified path. It might not have been downloaded yet or is in a different location.\")\n",
        "else:\n",
        "    # Calculate the MD5 checksum\n",
        "    hasher = hashlib.md5()\n",
        "    with open(file_path, 'rb') as f:\n",
        "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
        "            hasher.update(chunk)\n",
        "    calculated_checksum = hasher.hexdigest()\n",
        "\n",
        "    # The expected checksum was from the previous error message\n",
        "    expected_checksum = \"9a475053fed0c26ee95cd4525e50074c\"\n",
        "\n",
        "    print(f\"Calculated MD5 checksum: {calculated_checksum}\")\n",
        "    print(f\"Expected MD5 checksum:   {expected_checksum}\")\n",
        "\n",
        "    if calculated_checksum == expected_checksum:\n",
        "        print(\"MD5 checksums MATCH. The file is correct.\")\n",
        "    else:\n",
        "        print(\"MD5 checksums DO NOT MATCH. The file might be corrupted or outdated.\")"
      ],
      "id": "a698410f",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking MD5 for file: /root/scikit_learn_data/openml/openml.org/data/v1/download/31\n",
            "Error: File not found at the specified path. It might not have been downloaded yet or is in a different location.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e76aeeb",
        "outputId": "df8a262f-7adf-49d8-fc6b-604d4abeb902"
      },
      "source": [
        "data.frame.info()"
      ],
      "id": "8e76aeeb",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 21 columns):\n",
            " #   Column                  Non-Null Count  Dtype   \n",
            "---  ------                  --------------  -----   \n",
            " 0   checking_status         1000 non-null   category\n",
            " 1   duration                1000 non-null   float64 \n",
            " 2   credit_history          1000 non-null   category\n",
            " 3   purpose                 1000 non-null   category\n",
            " 4   credit_amount           1000 non-null   float64 \n",
            " 5   savings_status          1000 non-null   category\n",
            " 6   employment              1000 non-null   category\n",
            " 7   installment_commitment  1000 non-null   float64 \n",
            " 8   personal_status         1000 non-null   category\n",
            " 9   other_parties           1000 non-null   category\n",
            " 10  residence_since         1000 non-null   float64 \n",
            " 11  property_magnitude      1000 non-null   category\n",
            " 12  age                     1000 non-null   float64 \n",
            " 13  other_payment_plans     1000 non-null   category\n",
            " 14  housing                 1000 non-null   category\n",
            " 15  existing_credits        1000 non-null   float64 \n",
            " 16  job                     1000 non-null   category\n",
            " 17  num_dependents          1000 non-null   float64 \n",
            " 18  own_telephone           1000 non-null   category\n",
            " 19  foreign_worker          1000 non-null   category\n",
            " 20  class                   1000 non-null   category\n",
            "dtypes: category(14), float64(7)\n",
            "memory usage: 71.0 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "99a9b92b",
        "outputId": "3a9a63f2-c837-46f4-dafb-db333b3a9d5e"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.datasets import get_data_home\n",
        "\n",
        "# Get the scikit-learn data home directory\n",
        "data_home = get_data_home()\n",
        "\n",
        "# Construct the path to the OpenML cache directory\n",
        "openml_cache_dir = os.path.join(data_home, \"openml\")\n",
        "\n",
        "# Remove the entire OpenML cache directory if it exists\n",
        "if os.path.exists(openml_cache_dir):\n",
        "    print(f\"Removing OpenML cache directory: {openml_cache_dir}\")\n",
        "    shutil.rmtree(openml_cache_dir)\n",
        "else:\n",
        "    print(f\"OpenML cache directory not found: {openml_cache_dir}\")\n",
        "\n",
        "print(\"Retrying data fetch...\")\n",
        "# Now, retry fetching the data, which will force a fresh download\n",
        "data = fetch_openml(name=\"credit-g\", version=1, parser='auto')"
      ],
      "id": "99a9b92b",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing OpenML cache directory: /root/scikit_learn_data/openml\n",
            "Retrying data fetch...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "md5 checksum of local file for data/v1/download/31 does not match description: expected: 9a475053fed0c26ee95cd4525e50074c but got 4faec5c39a1f821270a5878880fbfc8c. Downloaded file could have been modified / corrupted, clean cache and retry...",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36m_load_arff_response\u001b[0;34m(url, data_home, parser, output_type, openml_columns_info, feature_names_to_select, target_names_to_select, shape, md5_checksum, n_retries, delay, read_csv_kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactual_md5_checksum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmd5_checksum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;34mf\"md5 checksum of local file for {url} does not match description: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: md5 checksum of local file for data/v1/download/31 does not match description: expected: 9a475053fed0c26ee95cd4525e50074c but got 4faec5c39a1f821270a5878880fbfc8c. Downloaded file could have been modified / corrupted, clean cache and retry...",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2895977105.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Retrying data fetch...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Now, retry fetching the data, which will force a fresh download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_openml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"credit-g\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36mfetch_openml\u001b[0;34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame, n_retries, delay, parser, read_csv_kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0;31m# obtain the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_DATA_FILE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_description\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m     bunch = _download_data_to_bunch(\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mreturn_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36m_download_data_to_bunch\u001b[0;34m(url, sparse, data_home, as_frame, openml_columns_info, data_columns, target_columns, shape, md5_checksum, n_retries, delay, parser, read_csv_kwargs)\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0mno_retry_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParserError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m     X, y, frame, categories = _retry_with_clean_cache(\n\u001b[0m\u001b[1;32m    685\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_home\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_retry_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_arff_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36m_load_arff_response\u001b[0;34m(url, data_home, parser, output_type, openml_columns_info, feature_names_to_select, target_names_to_select, shape, md5_checksum, n_retries, delay, read_csv_kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactual_md5_checksum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmd5_checksum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;34mf\"md5 checksum of local file for {url} does not match description: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;34mf\"expected: {md5_checksum} but got {actual_md5_checksum}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: md5 checksum of local file for data/v1/download/31 does not match description: expected: 9a475053fed0c26ee95cd4525e50074c but got 4faec5c39a1f821270a5878880fbfc8c. Downloaded file could have been modified / corrupted, clean cache and retry..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "fd40f860",
        "outputId": "040ed9ba-b3fd-4800-a01b-e746d30942a2"
      },
      "source": [
        "import os\n",
        "from sklearn.datasets import get_data_home\n",
        "\n",
        "# Get the scikit-learn data home directory\n",
        "data_home = get_data_home()\n",
        "\n",
        "# Construct the path to the downloaded file for 'credit-g'\n",
        "# The path is usually data_home/openml/openml.org/data/v1/download/{data_id}\n",
        "# From the error message, the data_id is 31.\n",
        "file_to_remove = os.path.join(data_home, \"openml\", \"openml.org\", \"data\", \"v1\", \"download\", \"31\")\n",
        "\n",
        "if os.path.exists(file_to_remove):\n",
        "    print(f\"Removing corrupted file: {file_to_remove}\")\n",
        "    os.remove(file_to_remove)\n",
        "else:\n",
        "    print(f\"File not found, no need to remove: {file_to_remove}\")\n",
        "\n",
        "# Now, retry fetching the data\n",
        "data = fetch_openml(name=\"credit-g\", version=1, parser='auto')"
      ],
      "id": "fd40f860",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File not found, no need to remove: /root/scikit_learn_data/openml/openml.org/data/v1/download/31\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "md5 checksum of local file for data/v1/download/31 does not match description: expected: 9a475053fed0c26ee95cd4525e50074c but got 4faec5c39a1f821270a5878880fbfc8c. Downloaded file could have been modified / corrupted, clean cache and retry...",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36m_load_arff_response\u001b[0;34m(url, data_home, parser, output_type, openml_columns_info, feature_names_to_select, target_names_to_select, shape, md5_checksum, n_retries, delay, read_csv_kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactual_md5_checksum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmd5_checksum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;34mf\"md5 checksum of local file for {url} does not match description: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: md5 checksum of local file for data/v1/download/31 does not match description: expected: 9a475053fed0c26ee95cd4525e50074c but got 4faec5c39a1f821270a5878880fbfc8c. Downloaded file could have been modified / corrupted, clean cache and retry...",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-950952909.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Now, retry fetching the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_openml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"credit-g\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36mfetch_openml\u001b[0;34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame, n_retries, delay, parser, read_csv_kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0;31m# obtain the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_DATA_FILE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_description\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m     bunch = _download_data_to_bunch(\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mreturn_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36m_download_data_to_bunch\u001b[0;34m(url, sparse, data_home, as_frame, openml_columns_info, data_columns, target_columns, shape, md5_checksum, n_retries, delay, parser, read_csv_kwargs)\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0mno_retry_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParserError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m     X, y, frame, categories = _retry_with_clean_cache(\n\u001b[0m\u001b[1;32m    685\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_home\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_retry_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_arff_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36m_load_arff_response\u001b[0;34m(url, data_home, parser, output_type, openml_columns_info, feature_names_to_select, target_names_to_select, shape, md5_checksum, n_retries, delay, read_csv_kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactual_md5_checksum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmd5_checksum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;34mf\"md5 checksum of local file for {url} does not match description: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;34mf\"expected: {md5_checksum} but got {actual_md5_checksum}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: md5 checksum of local file for data/v1/download/31 does not match description: expected: 9a475053fed0c26ee95cd4525e50074c but got 4faec5c39a1f821270a5878880fbfc8c. Downloaded file could have been modified / corrupted, clean cache and retry..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "58dbf7c2-f40b-4965-baac-6903a27ef622",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58dbf7c2-f40b-4965-baac-6903a27ef622",
        "outputId": "f11e007a-e2c5-4dcd-9afb-0f12a6876df8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manually downloaded credit-g dataset from OpenML\n"
          ]
        }
      ],
      "source": [
        "print(data.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "53de57ec-0fb6-4b51-9c27-696b059a1847",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53de57ec-0fb6-4b51-9c27-696b059a1847",
        "outputId": "8e227851-8fd3-4147-81ee-e76e8609258a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data url:   https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)\n",
            "Paper url:           https://dl.acm.org/doi/abs/10.1145/967900.968104\n"
          ]
        }
      ],
      "source": [
        "print(\"Original data url: \".ljust(20), data.details[\"original_data_url\"])\n",
        "print(\"Paper url: \".ljust(20), data.details[\"paper_url\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b2c2514-484e-46cb-aedc-89a301266f44",
      "metadata": {
        "id": "6b2c2514-484e-46cb-aedc-89a301266f44"
      },
      "source": [
        "### High-Level Data Inspection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a76af306-caba-403d-a9cb-b5de12573075",
      "metadata": {
        "id": "a76af306-caba-403d-a9cb-b5de12573075"
      },
      "source": [
        "Let's inspect the data to see high level details like data types and size. We also want to make sure there are no glaring issues (like a large number of null values)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "20fb82c4-ed8d-42f8-b386-c7ebdc9bf786",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20fb82c4-ed8d-42f8-b386-c7ebdc9bf786",
        "outputId": "d97aa351-323c-4973-f998-ee8ad30cfde3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 21 columns):\n",
            " #   Column                  Non-Null Count  Dtype   \n",
            "---  ------                  --------------  -----   \n",
            " 0   checking_status         1000 non-null   category\n",
            " 1   duration                1000 non-null   float64 \n",
            " 2   credit_history          1000 non-null   category\n",
            " 3   purpose                 1000 non-null   category\n",
            " 4   credit_amount           1000 non-null   float64 \n",
            " 5   savings_status          1000 non-null   category\n",
            " 6   employment              1000 non-null   category\n",
            " 7   installment_commitment  1000 non-null   float64 \n",
            " 8   personal_status         1000 non-null   category\n",
            " 9   other_parties           1000 non-null   category\n",
            " 10  residence_since         1000 non-null   float64 \n",
            " 11  property_magnitude      1000 non-null   category\n",
            " 12  age                     1000 non-null   float64 \n",
            " 13  other_payment_plans     1000 non-null   category\n",
            " 14  housing                 1000 non-null   category\n",
            " 15  existing_credits        1000 non-null   float64 \n",
            " 16  job                     1000 non-null   category\n",
            " 17  num_dependents          1000 non-null   float64 \n",
            " 18  own_telephone           1000 non-null   category\n",
            " 19  foreign_worker          1000 non-null   category\n",
            " 20  class                   1000 non-null   category\n",
            "dtypes: category(14), float64(7)\n",
            "memory usage: 71.0 KB\n"
          ]
        }
      ],
      "source": [
        "df = data.frame\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a384932a-40df-45f6-bfbc-a9cf6c708f1b",
      "metadata": {
        "id": "a384932a-40df-45f6-bfbc-a9cf6c708f1b"
      },
      "source": [
        "We see that there are 21 columns, each with 1000 non-null values. The first 20 columns are contextual fields with `Dtype` of `category` or `int64`, while the last field is actually the target variable, `class`, which we wish to predict.\n",
        "\n",
        "From the description (above), the `class` tells us whether a loan to a customer was \"good\" or \"bad\". We are anticipating that patterns in the contextual data, as well as their relationship to the class outcomes, can give insight into loan classification. In the following notebooks, we will build a loan classification model that seeks to encode these patterns and relationships in its weights, such that given a new loan application (context data), the model can predict whether the loan (if approved) will be good or bad in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a451c9a3-0390-4d5a-b687-c59f52445eb1",
      "metadata": {
        "id": "a451c9a3-0390-4d5a-b687-c59f52445eb1"
      },
      "source": [
        "### Data Preparation For Demonstrating Feast"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc4e7653-b118-44c3-ade3-f1b217b112fc",
      "metadata": {
        "id": "dc4e7653-b118-44c3-ade3-f1b217b112fc"
      },
      "source": [
        "At this point, it's important to bring up that Feast was developed primarily to work with production data. Feast requires datasets to have entities (in our case, IDs) and timestamps, which it uses in joins. Feast can support joining data on multiple entities (like primary keys in SQL), as well as \"created\" timestamps and \"event\" timestamps. However, in this example, we'll keep things more simple.\n",
        "\n",
        "In a real loan application scenario, the application fields (in a database) would be associated with a timestamp, while the actual loan outcome (label) would be determined much later and recorded separately with a different timestamp.\n",
        "\n",
        "In order to demonstrate Feast capabilities, such as point-in-time joins, we will mock IDs and timestamps for this data. For IDs, we will use the original dataframe index values. For the timestamps, we will generate random values between \"Tue Sep 24 12:00:00 2023\" and \"Wed Oct  9 12:00:00 2023\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "9d6ec4f6-9410-4858-a440-45dccaa0896b",
      "metadata": {
        "id": "9d6ec4f6-9410-4858-a440-45dccaa0896b"
      },
      "outputs": [],
      "source": [
        "# Make index into \"ID\" column\n",
        "df = df.reset_index(names=[\"ID\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "055f2cb7-3abf-4d01-be60-e4c7b8ad1988",
      "metadata": {
        "id": "055f2cb7-3abf-4d01-be60-e4c7b8ad1988"
      },
      "outputs": [],
      "source": [
        "# Add mock timestamps\n",
        "time_format = \"%a %b %d %H:%M:%S %Y\"\n",
        "date = dt.datetime.strptime(\"Wed Oct  9 12:00:00 2023\", time_format)\n",
        "end = int(date.timestamp())\n",
        "start = int((date - dt.timedelta(days=15)).timestamp())  # 'Tue Sep 24 12:00:00 2023'\n",
        "\n",
        "def make_tstamp(date):\n",
        "    dtime = dt.datetime.fromtimestamp(date).ctime()\n",
        "    return dtime\n",
        "\n",
        "# (seed set for reproducibility)\n",
        "np.random.seed(SEED)\n",
        "df[\"application_timestamp\"] = pd.to_datetime([\n",
        "    make_tstamp(d) for d in np.random.randint(start, end, len(df))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7800ea9-de9a-4aab-9d77-c4276e7db5f9",
      "metadata": {
        "id": "f7800ea9-de9a-4aab-9d77-c4276e7db5f9"
      },
      "source": [
        "Verify that the newly created \"ID\" and \"application_timestamp\" fields were added to the data as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9516fc5c-7c25-4e60-acba-7400ab6bab42",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "id": "9516fc5c-7c25-4e60-acba-7400ab6bab42",
        "outputId": "2cfb0164-295c-49cd-8dff-1c0356eee06b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     0                    1  \\\n",
              "ID                                                   0                    1   \n",
              "checking_status                                     <0             0<=X<200   \n",
              "duration                                           6.0                 48.0   \n",
              "credit_history          critical/other existing credit        existing paid   \n",
              "purpose                                       radio/tv             radio/tv   \n",
              "credit_amount                                   1169.0               5951.0   \n",
              "savings_status                        no known savings                 <100   \n",
              "employment                                         >=7               1<=X<4   \n",
              "installment_commitment                             4.0                  2.0   \n",
              "personal_status                            male single   female div/dep/mar   \n",
              "other_parties                                     none                 none   \n",
              "residence_since                                    4.0                  2.0   \n",
              "property_magnitude                         real estate          real estate   \n",
              "age                                               67.0                 22.0   \n",
              "other_payment_plans                               none                 none   \n",
              "housing                                            own                  own   \n",
              "existing_credits                                   2.0                  1.0   \n",
              "job                                            skilled              skilled   \n",
              "num_dependents                                     1.0                  1.0   \n",
              "own_telephone                                      yes                 none   \n",
              "foreign_worker                                     yes                  yes   \n",
              "class                                             good                  bad   \n",
              "application_timestamp              2023-10-04 17:50:13  2023-09-28 18:10:13   \n",
              "\n",
              "                                                     2  \n",
              "ID                                                   2  \n",
              "checking_status                            no checking  \n",
              "duration                                          12.0  \n",
              "credit_history          critical/other existing credit  \n",
              "purpose                                      education  \n",
              "credit_amount                                   2096.0  \n",
              "savings_status                                    <100  \n",
              "employment                                      4<=X<7  \n",
              "installment_commitment                             2.0  \n",
              "personal_status                            male single  \n",
              "other_parties                                     none  \n",
              "residence_since                                    3.0  \n",
              "property_magnitude                         real estate  \n",
              "age                                               49.0  \n",
              "other_payment_plans                               none  \n",
              "housing                                            own  \n",
              "existing_credits                                   1.0  \n",
              "job                                 unskilled resident  \n",
              "num_dependents                                     2.0  \n",
              "own_telephone                                     none  \n",
              "foreign_worker                                     yes  \n",
              "class                                             good  \n",
              "application_timestamp              2023-10-03 23:06:03  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c59cc2f-f39a-4c4a-866f-da084bafae6c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>checking_status</th>\n",
              "      <td>&lt;0</td>\n",
              "      <td>0&lt;=X&lt;200</td>\n",
              "      <td>no checking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>duration</th>\n",
              "      <td>6.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>credit_history</th>\n",
              "      <td>critical/other existing credit</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>critical/other existing credit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>purpose</th>\n",
              "      <td>radio/tv</td>\n",
              "      <td>radio/tv</td>\n",
              "      <td>education</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>credit_amount</th>\n",
              "      <td>1169.0</td>\n",
              "      <td>5951.0</td>\n",
              "      <td>2096.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>savings_status</th>\n",
              "      <td>no known savings</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>&lt;100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>employment</th>\n",
              "      <td>&gt;=7</td>\n",
              "      <td>1&lt;=X&lt;4</td>\n",
              "      <td>4&lt;=X&lt;7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>installment_commitment</th>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>personal_status</th>\n",
              "      <td>male single</td>\n",
              "      <td>female div/dep/mar</td>\n",
              "      <td>male single</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>other_parties</th>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>residence_since</th>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property_magnitude</th>\n",
              "      <td>real estate</td>\n",
              "      <td>real estate</td>\n",
              "      <td>real estate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>67.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>49.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>other_payment_plans</th>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>housing</th>\n",
              "      <td>own</td>\n",
              "      <td>own</td>\n",
              "      <td>own</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>existing_credits</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>job</th>\n",
              "      <td>skilled</td>\n",
              "      <td>skilled</td>\n",
              "      <td>unskilled resident</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_dependents</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>own_telephone</th>\n",
              "      <td>yes</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>foreign_worker</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <td>good</td>\n",
              "      <td>bad</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>application_timestamp</th>\n",
              "      <td>2023-10-04 17:50:13</td>\n",
              "      <td>2023-09-28 18:10:13</td>\n",
              "      <td>2023-10-03 23:06:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c59cc2f-f39a-4c4a-866f-da084bafae6c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c59cc2f-f39a-4c4a-866f-da084bafae6c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c59cc2f-f39a-4c4a-866f-da084bafae6c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-515c56b8-964c-483c-8be7-db42c42ee78f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-515c56b8-964c-483c-8be7-db42c42ee78f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-515c56b8-964c-483c-8be7-db42c42ee78f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Check data (first few records, transposed for readability)\n",
        "df.head(3).T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72b2105a-b459-4715-aa53-6fe69fc4a210",
      "metadata": {
        "id": "72b2105a-b459-4715-aa53-6fe69fc4a210"
      },
      "source": [
        "We'll also generate counterpart IDs and timestamps on the label data. In a real-life scenario, the label data would come separate and later relative to the loan application data. To mimic this, let's create a labels dataset with an \"outcome_timestamp\" column with a variable lag from the application timestamp of 30 to 90 days."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e214478b-ed9b-4354-ba6f-4117813c56c3",
      "metadata": {
        "id": "e214478b-ed9b-4354-ba6f-4117813c56c3"
      },
      "outputs": [],
      "source": [
        "# Add (lagged) label timestamps (30 to 90 days)\n",
        "def lag_delta(data, seed):\n",
        "    np.random.seed(seed)\n",
        "    delta_days = np.random.randint(30, 90, len(data))\n",
        "    delta_hours = np.random.randint(0, 24, len(data))\n",
        "    delta = np.array([dt.timedelta(days=int(delta_days[i]), hours=int(delta_hours[i])) for i in range(len(data))])\n",
        "    return delta\n",
        "\n",
        "labels = df[[\"ID\", \"class\"]]\n",
        "labels[\"outcome_timestamp\"] = pd.to_datetime(df.application_timestamp + lag_delta(df, SEED))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "356a7225-db20-4c15-87a3-4a0eb3127475",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "356a7225-db20-4c15-87a3-4a0eb3127475",
        "outputId": "9620b06d-0753-415f-a5e2-9f51deb8b321"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID class   outcome_timestamp\n",
              "0   0  good 2023-11-24 22:50:13\n",
              "1   1   bad 2023-11-03 12:10:13\n",
              "2   2  good 2023-11-30 22:06:03"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd3749b5-091f-478e-869e-0c5f2932391c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>class</th>\n",
              "      <th>outcome_timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>good</td>\n",
              "      <td>2023-11-24 22:50:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>bad</td>\n",
              "      <td>2023-11-03 12:10:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>good</td>\n",
              "      <td>2023-11-30 22:06:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd3749b5-091f-478e-869e-0c5f2932391c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd3749b5-091f-478e-869e-0c5f2932391c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd3749b5-091f-478e-869e-0c5f2932391c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4a5f2e7c-3b0d-43b4-8826-03c332edb5bb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a5f2e7c-3b0d-43b4-8826-03c332edb5bb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4a5f2e7c-3b0d-43b4-8826-03c332edb5bb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "labels",
              "summary": "{\n  \"name\": \"labels\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 288,\n        \"min\": 0,\n        \"max\": 999,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          521,\n          737,\n          740\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"bad\",\n          \"good\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"outcome_timestamp\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-10-25 17:31:03\",\n        \"max\": \"2024-01-06 12:38:03\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"2023-10-29 05:11:40\",\n          \"2023-12-08 21:18:47\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Check labels\n",
        "labels.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a29f754-f758-402b-ac42-2dcfcee3b7fc",
      "metadata": {
        "id": "4a29f754-f758-402b-ac42-2dcfcee3b7fc"
      },
      "source": [
        "You can verify that the `outcome timestamp` has a difference of 30 to 90 days from the \"application_timestamp\" (above)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e720ce24-e092-4fcd-be3e-68bb18f4d2a7",
      "metadata": {
        "id": "e720ce24-e092-4fcd-be3e-68bb18f4d2a7"
      },
      "source": [
        "### Save Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cae0578-8431-46c7-8d64-e52146f47d46",
      "metadata": {
        "id": "5cae0578-8431-46c7-8d64-e52146f47d46"
      },
      "source": [
        "Now that we have our data prepared, let's save it to local parquet files in the `data` directory (parquet is one of the file formats supported by Feast).\n",
        "\n",
        "One more step we will add is splitting the context data column-wise and saving it in two files. This step is contrived--we don't usually split data when we don't need to--but it will allow us to demonstrate later how Feast can easily join datasets (a common need in Data Science projects)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "cebef56c-1f54-4d31-a545-75d708d38579",
      "metadata": {
        "id": "cebef56c-1f54-4d31-a545-75d708d38579"
      },
      "outputs": [],
      "source": [
        "# Create the data directory if it doesn't exist\n",
        "os.makedirs(\"Feature_Store/data\", exist_ok=True)\n",
        "\n",
        "# Split columns and save context data\n",
        "a_cols = [\n",
        "    'ID', 'checking_status', 'duration', 'credit_history', 'purpose',\n",
        "    'credit_amount', 'savings_status', 'employment', 'application_timestamp',\n",
        "    'installment_commitment', 'personal_status', 'other_parties',\n",
        "]\n",
        "b_cols = [\n",
        "    'ID', 'residence_since', 'property_magnitude', 'age', 'other_payment_plans',\n",
        "    'housing', 'existing_credits', 'job', 'num_dependents', 'own_telephone',\n",
        "    'foreign_worker', 'application_timestamp'\n",
        "]\n",
        "\n",
        "df[a_cols].to_parquet(\"Feature_Store/data/data_a.parquet\", engine=\"pyarrow\")\n",
        "df[b_cols].to_parquet(\"Feature_Store/data/data_b.parquet\", engine=\"pyarrow\")\n",
        "\n",
        "# Save label data\n",
        "labels.to_parquet(\"Feature_Store/data/labels.parquet\", engine=\"pyarrow\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8d5de9f-bd27-4e95-802c-b121743dd1b0",
      "metadata": {
        "id": "d8d5de9f-bd27-4e95-802c-b121743dd1b0"
      },
      "source": [
        "We have saved the following files to the `Feature_Store/data` directory:\n",
        "- `data_a.parquet` (training data, a columns)\n",
        "- `data_b.parquet` (training data, b columns)\n",
        "- `labels.parquet` (label outcomes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af6355dc-ff5b-4b3f-b0bd-3c4020ef67e8",
      "metadata": {
        "id": "af6355dc-ff5b-4b3f-b0bd-3c4020ef67e8"
      },
      "source": [
        "With the feature data prepared, we are ready to setup and deploy the feature store.\n",
        "\n",
        "Continue with the [02_Deploying_the_Feature_Store.ipynb](02_Deploying_the_Feature_Store.ipynb) notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51eca67d"
      },
      "source": [
        "# Task\n",
        "Manually download the ARFF file for the \"credit-g\" dataset from OpenML and load it into a pandas DataFrame, ensuring the resulting `data` object mimics the output structure of `fetch_openml`, and install 'requests' and 'scipy' for this purpose."
      ],
      "id": "51eca67d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfb55239"
      },
      "source": [
        "## Modify_fetch_openml_cell\n",
        "\n",
        "### Subtask:\n",
        "Replace the existing fetch_openml call with code to manually download the ARFF file and load it into a pandas DataFrame, mimicking the structure of fetch_openml output.\n"
      ],
      "id": "cfb55239"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75193e68"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempts to fetch data using `fetch_openml` failed due to checksum mismatches. To resolve this and proceed with the subtask, I will manually download the ARFF file, process it, and encapsulate it in a `Bunch` object, mimicking the output structure of `fetch_openml`, as per the instructions.\n",
        "\n"
      ],
      "id": "75193e68"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "58474b88",
        "outputId": "7e1fc6c6-2640-445c-d15b-46e33ee64ee7"
      },
      "source": [
        "import requests\n",
        "from scipy.io import arff\n",
        "import pandas as pd\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "# 1. Import necessary libraries (already done above, but kept for context)\n",
        "\n",
        "# 2. Define the URL for the 'credit-g' ARFF file\n",
        "arff_url = \"https://www.openml.org/data/v1/download/31\"\n",
        "\n",
        "# Define a simple Bunch class to mimic sklearn's return type\n",
        "class Bunch(dict):\n",
        "    \"\"\"Container object for datasets\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(kwargs)\n",
        "\n",
        "    def __setattr__(self, key, value):\n",
        "        self[key] = value\n",
        "\n",
        "    def __dir__(self):\n",
        "        return self.keys()\n",
        "\n",
        "    def __getattr__(self, key):\n",
        "        try:\n",
        "            return self[key]\n",
        "        except KeyError:\n",
        "            raise AttributeError(key)\n",
        "\n",
        "# 3. Create a temporary file to store the downloaded ARFF content\n",
        "# 4. Download the ARFF file content\n",
        "# 5. Load the ARFF file from the temporary path\n",
        "with tempfile.NamedTemporaryFile(delete=True, suffix=\".arff\") as temp_arff_file:\n",
        "    print(f\"Downloading ARFF file from {arff_url} to {temp_arff_file.name}...\")\n",
        "    response = requests.get(arff_url)\n",
        "    response.raise_for_status() # Raise an exception for bad status codes\n",
        "    temp_arff_file.write(response.content)\n",
        "    temp_arff_file.flush()\n",
        "\n",
        "    print(\"Loading ARFF data...\")\n",
        "    arff_data, meta = arff.loadarff(temp_arff_file.name)\n",
        "    print(\"ARFF data loaded.\")\n",
        "\n",
        "# 6. Convert the loaded data into a pandas DataFrame.\n",
        "frame = pd.DataFrame(arff_data)\n",
        "\n",
        "# 7. Iterate through the DataFrame's columns, decode byte strings, and convert to category\n",
        "for col in frame.columns:\n",
        "    if frame[col].dtype == object:\n",
        "        try:\n",
        "            # Check if the first non-null value is bytes type\n",
        "            first_val = frame[col].dropna().iloc[0]\n",
        "            if isinstance(first_val, bytes):\n",
        "                frame[col] = frame[col].apply(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
        "                frame[col] = frame[col].astype('category')\n",
        "        except IndexError: # Column might be entirely null\n",
        "            pass\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process column '{col}': {e}\")\n",
        "\n",
        "# 8. Define a simple class named `Bunch` (already defined above)\n",
        "\n",
        "# 9. Create an instance of this `Bunch` class.\n",
        "data = Bunch()\n",
        "\n",
        "# 10. Populate the `data` object with the required attributes\n",
        "data.frame = frame\n",
        "data.data = frame.drop(columns=['class'])\n",
        "data.target = frame['class']\n",
        "data.DESCR = 'Manually downloaded credit-g dataset from OpenML'\n",
        "data.details = {\n",
        "    'original_data_url': 'https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)',\n",
        "    'paper_url': 'https://dl.acm.org/doi/abs/10.1145/967900.968104'\n",
        "}\n",
        "\n",
        "print(\"Data successfully downloaded, processed, and structured in 'data' object.\")\n"
      ],
      "id": "58474b88",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-1629977571.py, line 14)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1629977571.py\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    \"\"\"Container object for datasets\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ead5713b"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed due to a `SyntaxError` in the docstring of the `Bunch` class. I will fix the incomplete multiline string by correcting the closing triple quotes.\n",
        "\n"
      ],
      "id": "ead5713b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ab68273",
        "outputId": "1942a042-cbbf-499b-cce0-69c37b6ec3d1"
      },
      "source": [
        "import requests\n",
        "from scipy.io import arff\n",
        "import pandas as pd\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "# 1. Import necessary libraries (already done above, but kept for context)\n",
        "\n",
        "# 2. Define the URL for the 'credit-g' ARFF file\n",
        "arff_url = \"https://www.openml.org/data/v1/download/31\"\n",
        "\n",
        "# Define a simple Bunch class to mimic sklearn's return type\n",
        "class Bunch(dict):\n",
        "    \"\"\"Container object for datasets\"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(kwargs)\n",
        "\n",
        "    def __setattr__(self, key, value):\n",
        "        self[key] = value\n",
        "\n",
        "    def __dir__(self):\n",
        "        return self.keys()\n",
        "\n",
        "    def __getattr__(self, key):\n",
        "        try:\n",
        "            return self[key]\n",
        "        except KeyError:\n",
        "            raise AttributeError(key)\n",
        "\n",
        "# 3. Create a temporary file to store the downloaded ARFF content\n",
        "# 4. Download the ARFF file content\n",
        "# 5. Load the ARFF file from the temporary path\n",
        "with tempfile.NamedTemporaryFile(delete=True, suffix=\".arff\") as temp_arff_file:\n",
        "    print(f\"Downloading ARFF file from {arff_url} to {temp_arff_file.name}...\")\n",
        "    response = requests.get(arff_url)\n",
        "    response.raise_for_status() # Raise an exception for bad status codes\n",
        "    temp_arff_file.write(response.content)\n",
        "    temp_arff_file.flush()\n",
        "\n",
        "    print(\"Loading ARFF data...\")\n",
        "    arff_data, meta = arff.loadarff(temp_arff_file.name)\n",
        "    print(\"ARFF data loaded.\")\n",
        "\n",
        "# 6. Convert the loaded data into a pandas DataFrame.\n",
        "frame = pd.DataFrame(arff_data)\n",
        "\n",
        "# 7. Iterate through the DataFrame's columns, decode byte strings, and convert to category\n",
        "for col in frame.columns:\n",
        "    if frame[col].dtype == object:\n",
        "        try:\n",
        "            # Check if the first non-null value is bytes type\n",
        "            first_val = frame[col].dropna().iloc[0]\n",
        "            if isinstance(first_val, bytes):\n",
        "                frame[col] = frame[col].apply(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
        "                frame[col] = frame[col].astype('category')\n",
        "        except IndexError: # Column might be entirely null\n",
        "            pass\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process column '{col}': {e}\")\n",
        "\n",
        "# 8. Define a simple class named `Bunch` (already defined above)\n",
        "\n",
        "# 9. Create an instance of this `Bunch` class.\n",
        "data = Bunch()\n",
        "\n",
        "# 10. Populate the `data` object with the required attributes\n",
        "data.frame = frame\n",
        "data.data = frame.drop(columns=['class'])\n",
        "data.target = frame['class']\n",
        "data.DESCR = 'Manually downloaded credit-g dataset from OpenML'\n",
        "data.details = {\n",
        "    'original_data_url': 'https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)',\n",
        "    'paper_url': 'https://dl.acm.org/doi/abs/10.1145/967900.968104'\n",
        "}\n",
        "\n",
        "print(\"Data successfully downloaded, processed, and structured in 'data' object.\")"
      ],
      "id": "5ab68273",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ARFF file from https://www.openml.org/data/v1/download/31 to /tmp/tmp863hq5g7.arff...\n",
            "Loading ARFF data...\n",
            "ARFF data loaded.\n",
            "Data successfully downloaded, processed, and structured in 'data' object.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a03ef313"
      },
      "source": [
        "## Install_dependencies\n",
        "\n",
        "### Subtask:\n",
        "Ensure 'requests' and 'scipy' libraries are installed, as they are used for manual download and ARFF parsing.\n"
      ],
      "id": "a03ef313"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e231e337"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The \"credit-g\" ARFF dataset was successfully downloaded from `https://www.openml.org/data/v1/download/31` using the `requests` library.\n",
        "*   The downloaded ARFF data was loaded and parsed into a pandas DataFrame using `scipy.io.arff.loadarff`.\n",
        "*   All byte-string columns within the DataFrame were correctly decoded to UTF-8 and converted into the 'category' data type to ensure proper data handling.\n",
        "*   A custom `Bunch` class was implemented to replicate the output structure of `fetch_openml`, allowing the processed data to be accessed via attributes like `data.frame`, `data.data`, `data.target`, `data.DESCR`, and `data.details`.\n",
        "*   The resulting `data` object successfully mimicked the `fetch_openml` output, with `data.data` containing the features (all columns except 'class') and `data.target` holding the 'class' column.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The successful manual download and structuring provide a robust fallback mechanism for obtaining datasets when standard library functions like `fetch_openml` might not be directly applicable or available.\n",
        "*   Maintaining a consistent data structure, even with custom loading methods, ensures seamless integration with downstream machine learning pipelines that expect a `fetch_openml`-like `Bunch` object.\n"
      ],
      "id": "e231e337"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}